{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score,r2_score,mean_absolute_error,mean_squared_error,accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict\n",
    "from sklearn import svm,metrics,tree,preprocessing,linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error,recall_score,confusion_matrix,f1_score,roc_curve, auc\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../../../Atliq Marts Challenge'\n",
    "fact_order_lines_df=pd.read_csv(path+\"/fact_order_lines.csv\")\n",
    "# fact_orders_aggregate_df=pd.read_csv(\"Atliq Marts Challenge/fact_orders_aggregate.csv\")\n",
    "\n",
    "dim_date=pd.read_csv(path+\"/dim_date.csv\")\n",
    "dim_customers=pd.read_csv(path+\"/dim_customers.csv\")\n",
    "dim_products=pd.read_csv(path+\"/dim_products.csv\")\n",
    "dim_targets_orders=pd.read_csv(path+\"/dim_targets_orders.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result =  pd.concat([fact_order_lines_df, fact_orders_aggregate_df], axis=1,join=\"outer\")\n",
    "# result =pd.merge( fact_order_lines_df, fact_orders_aggregate_df, on=[\"order_id\", \"customer_id\"])\n",
    "# esult =pd.merge( fact_order_lines_df, fact_orders_aggregate_df, on=[\"order_id\", \"customer_id\"])\n",
    "result =pd.merge( fact_order_lines_df ,dim_customers , how=\"outer\",on=[\"customer_id\"])\n",
    "result =pd.merge( result ,dim_products , how=\"outer\",on=[\"product_id\"])\n",
    "train_SC =pd.merge( result ,dim_targets_orders , how=\"outer\",on=[\"customer_id\"])\n",
    "train_SC =pd.merge( result ,dim_targets_orders , how=\"outer\",on=[\"customer_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SC.columns = [col.lower().replace(' ', '_') for col in train_SC.columns]\n",
    "train_SC.rename(columns=lambda x: x.replace(\"(\", \"\").replace(\")\", \"\"), inplace=True)\n",
    "train_SC.rename(columns=lambda x: x.replace(\"%\", \"_percent\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57096 entries, 0 to 57095\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   order_id               57096 non-null  object\n",
      " 1   order_placement_date   57096 non-null  object\n",
      " 2   customer_id            57096 non-null  int64 \n",
      " 3   product_id             57096 non-null  int64 \n",
      " 4   order_qty              57096 non-null  int64 \n",
      " 5   agreed_delivery_date   57096 non-null  object\n",
      " 6   actual_delivery_date   57096 non-null  object\n",
      " 7   delivery_qty           57096 non-null  int64 \n",
      " 8   in_full                57096 non-null  int64 \n",
      " 9   on_time                57096 non-null  int64 \n",
      " 10  on_time_in_full        57096 non-null  int64 \n",
      " 11  customer_name          57096 non-null  object\n",
      " 12  city                   57096 non-null  object\n",
      " 13  product_name           57096 non-null  object\n",
      " 14  category               57096 non-null  object\n",
      " 15  ontime_target_percent  57096 non-null  int64 \n",
      " 16  infull_target_percent  57096 non-null  int64 \n",
      " 17  otif_target_percent    57096 non-null  int64 \n",
      "dtypes: int64(10), object(8)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_SC.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Agency_25</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1264.162234</td>\n",
       "      <td>1152.473405</td>\n",
       "      <td>111.688829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.835008</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>99.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Agency_29</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>8.7480</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>498567142</td>\n",
       "      <td>762225057</td>\n",
       "      <td>27.584615</td>\n",
       "      <td>1316.098485</td>\n",
       "      <td>1296.804924</td>\n",
       "      <td>19.293561</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>177</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168825</td>\n",
       "      <td>1634.434615</td>\n",
       "      <td>11.397086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>Agency_47</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>4.9680</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>454252482</td>\n",
       "      <td>789624076</td>\n",
       "      <td>30.665957</td>\n",
       "      <td>1269.250000</td>\n",
       "      <td>1266.490490</td>\n",
       "      <td>2.759510</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.217413</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.603017</td>\n",
       "      <td>2625.472644</td>\n",
       "      <td>48.295650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Agency_53</td>\n",
       "      <td>SKU_07</td>\n",
       "      <td>21.6825</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>480693900</td>\n",
       "      <td>791658684</td>\n",
       "      <td>29.197727</td>\n",
       "      <td>1193.842373</td>\n",
       "      <td>1128.124395</td>\n",
       "      <td>65.717978</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>beer_capital</td>\n",
       "      <td>-</td>\n",
       "      <td>5.504745</td>\n",
       "      <td>240</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3.076505</td>\n",
       "      <td>38.529107</td>\n",
       "      <td>2511.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>Agency_17</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>960.5520</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>515468092</td>\n",
       "      <td>871204688</td>\n",
       "      <td>23.608120</td>\n",
       "      <td>1338.334248</td>\n",
       "      <td>1232.128069</td>\n",
       "      <td>106.206179</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>7.935699</td>\n",
       "      <td>259</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6.867508</td>\n",
       "      <td>2143.677462</td>\n",
       "      <td>396.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>1184.6535</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>425528909</td>\n",
       "      <td>734443953</td>\n",
       "      <td>28.668254</td>\n",
       "      <td>1369.556376</td>\n",
       "      <td>1161.135214</td>\n",
       "      <td>208.421162</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.218151</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7.077206</td>\n",
       "      <td>1566.643589</td>\n",
       "      <td>1881.866367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>5.5593</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>623319783</td>\n",
       "      <td>1049868815</td>\n",
       "      <td>31.915385</td>\n",
       "      <td>1922.486644</td>\n",
       "      <td>1651.307674</td>\n",
       "      <td>271.178970</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>14.105636</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1.715472</td>\n",
       "      <td>1385.225478</td>\n",
       "      <td>109.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>Agency_48</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>4275.1605</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>509281531</td>\n",
       "      <td>892192092</td>\n",
       "      <td>26.767857</td>\n",
       "      <td>1761.258209</td>\n",
       "      <td>1546.059670</td>\n",
       "      <td>215.198539</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>12.218455</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.360577</td>\n",
       "      <td>1757.950603</td>\n",
       "      <td>1925.272108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>Agency_07</td>\n",
       "      <td>SKU_21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>544203593</td>\n",
       "      <td>761469815</td>\n",
       "      <td>28.987755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2418.719550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12084</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>46.3608</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>589969396</td>\n",
       "      <td>940912941</td>\n",
       "      <td>32.478910</td>\n",
       "      <td>1675.922116</td>\n",
       "      <td>1413.571789</td>\n",
       "      <td>262.350327</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.654088</td>\n",
       "      <td>181</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3.836454</td>\n",
       "      <td>2034.293024</td>\n",
       "      <td>109.381800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          agency     sku     volume       date  industry_volume  soda_volume  \\\n",
       "291    Agency_25  SKU_03     0.5076 2013-01-01        492612703    718394219   \n",
       "871    Agency_29  SKU_02     8.7480 2015-01-01        498567142    762225057   \n",
       "19532  Agency_47  SKU_01     4.9680 2013-09-01        454252482    789624076   \n",
       "2089   Agency_53  SKU_07    21.6825 2013-10-01        480693900    791658684   \n",
       "9755   Agency_17  SKU_02   960.5520 2015-03-01        515468092    871204688   \n",
       "7561   Agency_05  SKU_03  1184.6535 2014-02-01        425528909    734443953   \n",
       "19204  Agency_11  SKU_05     5.5593 2017-08-01        623319783   1049868815   \n",
       "8781   Agency_48  SKU_04  4275.1605 2013-03-01        509281531    892192092   \n",
       "2540   Agency_07  SKU_21     0.0000 2015-10-01        544203593    761469815   \n",
       "12084  Agency_21  SKU_03    46.3608 2017-04-01        589969396    940912941   \n",
       "\n",
       "       avg_max_temp  price_regular  price_actual    discount  ...  \\\n",
       "291       25.845238    1264.162234   1152.473405  111.688829  ...   \n",
       "871       27.584615    1316.098485   1296.804924   19.293561  ...   \n",
       "19532     30.665957    1269.250000   1266.490490    2.759510  ...   \n",
       "2089      29.197727    1193.842373   1128.124395   65.717978  ...   \n",
       "9755      23.608120    1338.334248   1232.128069  106.206179  ...   \n",
       "7561      28.668254    1369.556376   1161.135214  208.421162  ...   \n",
       "19204     31.915385    1922.486644   1651.307674  271.178970  ...   \n",
       "8781      26.767857    1761.258209   1546.059670  215.198539  ...   \n",
       "2540      28.987755       0.000000      0.000000    0.000000  ...   \n",
       "12084     32.478910    1675.922116   1413.571789  262.350327  ...   \n",
       "\n",
       "       football_gold_cup  beer_capital  music_fest discount_in_percent  \\\n",
       "291                    -             -           -            8.835008   \n",
       "871                    -             -           -            1.465966   \n",
       "19532                  -             -           -            0.217413   \n",
       "2089                   -  beer_capital           -            5.504745   \n",
       "9755                   -             -  music_fest            7.935699   \n",
       "7561                   -             -           -           15.218151   \n",
       "19204                  -             -           -           14.105636   \n",
       "8781                   -             -  music_fest           12.218455   \n",
       "2540                   -             -           -            0.000000   \n",
       "12084                  -             -           -           15.654088   \n",
       "\n",
       "      timeseries time_idx month log_volume avg_volume_by_sku  \\\n",
       "291          228        0     1  -0.678062       1225.306376   \n",
       "871          177       24     1   2.168825       1634.434615   \n",
       "19532        322        8     9   1.603017       2625.472644   \n",
       "2089         240        9    10   3.076505         38.529107   \n",
       "9755         259       26     3   6.867508       2143.677462   \n",
       "7561          21       13     2   7.077206       1566.643589   \n",
       "19204         17       55     8   1.715472       1385.225478   \n",
       "8781         151        2     3   8.360577       1757.950603   \n",
       "2540         300       33    10 -18.420681          0.000000   \n",
       "12084        181       51     4   3.836454       2034.293024   \n",
       "\n",
       "      avg_volume_by_agency  \n",
       "291              99.650400  \n",
       "871              11.397086  \n",
       "19532            48.295650  \n",
       "2089           2511.035175  \n",
       "9755            396.022140  \n",
       "7561           1881.866367  \n",
       "19204           109.699200  \n",
       "8781           1925.272108  \n",
       "2540           2418.719550  \n",
       "12084           109.381800  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = get_stallion_data()\n",
    "\n",
    "# add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "\n",
    "# add additional features\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"agency\"], observed=True).volume.transform(\"mean\")\n",
    "\n",
    "# we want to encode special days as one variable and thus need to first reverse one-hot encoding\n",
    "special_days = [\n",
    "    \"easter_day\",\n",
    "    \"good_friday\",\n",
    "    \"new_year\",\n",
    "    \"christmas\",\n",
    "    \"labor_day\",\n",
    "    \"independence_day\",\n",
    "    \"revolution_day_memorial\",\n",
    "    \"regional_games\",\n",
    "    \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\",\n",
    "    \"beer_capital\",\n",
    "    \"music_fest\",\n",
    "]\n",
    "data[special_days] = data[special_days].apply(lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")\n",
    "data.sample(10, random_state=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    "    static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(293.0089, device='mps:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "baseline_predictions = Baseline().predict(val_dataloader, return_y=True)\n",
    "MAE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 13.5k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"Ranger\"\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac49831aca74c1aa8367f1ee5cc9a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.12882495516931336\n",
      "Restoring states from the checkpoint path at /Users/narongdaetdata/Documents/patternProj/project-pattern/project-pattern-jacky/Atliq_Mart_Challenge_1/.lr_find_942e83d2-deb0-4bb6-bd2b-0d10bbe63847.ckpt\n",
      "Restored all states from the checkpoint at /Users/narongdaetdata/Documents/patternProj/project-pattern/project-pattern-jacky/Atliq_Mart_Challenge_1/.lr_find_942e83d2-deb0-4bb6-bd2b-0d10bbe63847.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.12882495516931336\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.4k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \n",
      "3  | prescalers                         | ModuleDict                      | 256   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808   \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "29.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.4 K    Total params\n",
      "0.118     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21c8cedc0e04998b588e1a56259cccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431f065acb4f43a08519c2114ed0d370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424e9971cc934ec2a75bc19268063c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716522c34f2d4e0bb31d9f42a3096179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6890e2b60cd40e980677e6e2c626d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c65f8c535f4b738bae6588645475eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82aa009558e9499aa5a1b128e822c212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350467cfbe554ad29b9e70ba4931bdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad23c9c7f6c423791f595f3d7455cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dc6fa091ed4492945239d47c8cbb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e749a3736b44e5599ddef40c6933b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aee107f36b4a91a5b93ba41521884c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b166a9b61446f58969183ef0b307be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44958737f1949c1b407c62c9fc5f446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdda0289ea464519b49076484f7bad20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e89f6b3b22b47c4b77a661ad15e06c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7179f225b94bd5850c6e9f2cfcd679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3b4d77c57e4ca79445cd6849363ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff132fc2bc543ada689390bb465218e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorboard.compat.tensorflow_stub.io.gfile' has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:997\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m    996\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 997\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: calling teardown hooks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1000\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_teardown_hook(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:517\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.on_fit_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_end\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 517\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:852\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.log_embeddings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_embeddings\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    851\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39membedding_labels[name]\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_step\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/tensorboard/writer.py:943\u001b[0m, in \u001b[0;36mSummaryWriter.add_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    941\u001b[0m         metadata\n\u001b[1;32m    942\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#labels should equal with #data points\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 943\u001b[0m     \u001b[43mmake_tsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_header\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    947\u001b[0m         mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m label_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    948\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#images should equal with #data points\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/tensorboard/_embedding.py:33\u001b[0m, in \u001b[0;36mmake_tsv\u001b[0;34m(metadata, save_path, metadata_header)\u001b[0m\n\u001b[1;32m     30\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m [metadata_header] \u001b[38;5;241m+\u001b[39m metadata]\n\u001b[1;32m     32\u001b[0m metadata_bytes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_bytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(metadata) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(\u001b[43m_gfile_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     34\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(metadata_bytes)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/tensorboard/_embedding.py:17\u001b[0m, in \u001b[0;36m_gfile_join\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gfile_join\u001b[39m(a, b):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# The join API is different between tensorboard's TF stub and TF:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# https://github.com/tensorflow/tensorboard/issues/6080\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# We need to try both because `tf` may point to either the stub or the real TF.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _HAS_GFILE_JOIN:\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m(a, b)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         fs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mget_filesystem(a)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard.compat.tensorflow_stub.io.gfile' has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-13 18:59:36,088] A new study created in memory with name: no-name-38fc9a0e-3c3d-4892-b8e3-6fda9678a3fe\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2024-04-13 18:59:36,856] Trial 0 failed with parameters: {'gradient_clip_val': 0.7734383456220956, 'hidden_size': 27, 'dropout': 0.117165868781584, 'hidden_continuous_size': 12, 'attention_head_size': 4, 'learning_rate': 0.07317301309273248} because of the following error: NotImplementedError(\"The operator 'aten::_embedding_bag' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py\", line 199, in objective\n",
      "    trainer.fit(model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py\", line 987, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py\", line 1031, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py\", line 1060, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/loops/utilities.py\", line 182, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/loops/evaluation_loop.py\", line 135, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/loops/evaluation_loop.py\", line 396, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/strategies/strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py\", line 630, in validation_step\n",
      "    log, out = self.step(x, y, batch_idx)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py\", line 777, in step\n",
      "    out = self(x, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py\", line 408, in forward\n",
      "    input_vectors = self.input_embeddings(x_cat)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/nn/embeddings.py\", line 181, in forward\n",
      "    input_vectors[name] = emb(\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/nn/embeddings.py\", line 21, in forward\n",
      "    y = super().forward(x_reshape)\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/sparse.py\", line 389, in forward\n",
      "    return F.embedding_bag(input, self.weight, offsets,\n",
      "  File \"/Users/narongdaetdata/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py\", line 2392, in embedding_bag\n",
      "    ret, _, _, _ = torch.embedding_bag(\n",
      "NotImplementedError: The operator 'aten::_embedding_bag' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\n",
      "[W 2024-04-13 18:59:36,916] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_embedding_bag' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemporal_fusion_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_hyperparameters\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# create study\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_clip_val_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_continuous_size_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_head_size_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlimit_train_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_on_plateau_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_learning_rate_finder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use Optuna to find ideal learning rate or use in-built learning rate finder\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# save study results - also we can resume tuning at a later point in time\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_study.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:207\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[0;34m(train_dataloaders, val_dataloaders, model_path, max_epochs, n_trials, timeout, gradient_clip_val_range, hidden_size_range, hidden_continuous_size_range, attention_head_size_range, dropout_range, learning_rate_range, use_learning_rate_finder, trainer_kwargs, log_dir, study, verbose, pruner, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m study \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[0;32m--> 207\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:199\u001b[0m, in \u001b[0;36moptimize_hyperparameters.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    196\u001b[0m     model\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39mlearning_rate_range)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# report result\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py:630\u001b[0m, in \u001b[0;36mBaseModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    629\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 630\u001b[0m     log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     log\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_log(x, y, out, batch_idx))\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step_outputs\u001b[38;5;241m.\u001b[39mappend(log)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/base_model.py:777\u001b[0m, in \u001b[0;36mBaseModel.step\u001b[0;34m(self, x, y, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 777\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:408\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    406\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m x_cont\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# encode + decode length\u001b[39;00m\n\u001b[1;32m    407\u001b[0m max_encoder_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(encoder_lengths\u001b[38;5;241m.\u001b[39mmax())\n\u001b[0;32m--> 408\u001b[0m input_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m input_vectors\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    410\u001b[0m     {\n\u001b[1;32m    411\u001b[0m         name: x_cont[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     }\n\u001b[1;32m    415\u001b[0m )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Embedding and variable selection\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/nn/embeddings.py:181\u001b[0m, in \u001b[0;36mMultiEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_groups:\n\u001b[0;32m--> 181\u001b[0m         input_vectors[name] \u001b[38;5;241m=\u001b[39m \u001b[43memb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_categoricals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_groups\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m         input_vectors[name] \u001b[38;5;241m=\u001b[39m emb(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_categoricals\u001b[38;5;241m.\u001b[39mindex(name)])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_forecasting/models/nn/embeddings.py:21\u001b[0m, in \u001b[0;36mTimeDistributedEmbeddingBag.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Squash samples and timesteps into a single axis\u001b[39;00m\n\u001b[1;32m     19\u001b[0m x_reshape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (samples * timesteps, input_size)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_reshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# We have to reshape Y\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/sparse.py:389\u001b[0m, in \u001b[0;36mEmbeddingBag.forward\u001b[0;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, offsets: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, per_sample_weights: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of EmbeddingBag.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m          returned vectors filled by zeros.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_bag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mper_sample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_last_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:2392\u001b[0m, in \u001b[0;36membedding_bag\u001b[0;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m per_sample_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   2387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_bag: per_sample_weights was not None. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper_sample_weights is only supported for mode=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got mode=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m). Please open a feature request on GitHub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mode)\n\u001b[1;32m   2390\u001b[0m     )\n\u001b[0;32m-> 2392\u001b[0m ret, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_bag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_sample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_last_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_embedding_bag' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "MAE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
